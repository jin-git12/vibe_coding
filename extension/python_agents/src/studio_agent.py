"""
LangGraph Studio å…¥å£ç‚¹
æä¾›ä¸€ä¸ªå¯è§‚æµ‹çš„ Agent å®ä¾‹ä¾› Studio ä½¿ç”¨

é…ç½® LangSmith Tracing ä»¥è§‚æµ‹ Subagentï¼š
1. åœ¨ .env ä¸­è®¾ç½® LANGSMITH_TRACING=true
2. åœ¨ .env ä¸­è®¾ç½® LANGSMITH_API_KEY=<your_key>
3. è¿è¡Œ langgraph dev åï¼Œåœ¨ https://smith.langchain.com æŸ¥çœ‹å®Œæ•´ trace
"""
import os
import sys
from pathlib import Path

# æ·»åŠ  src ç›®å½•åˆ° Python è·¯å¾„
src_dir = Path(__file__).parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from agents.unified_agent import create_unified_chat_agent
from agents.code_agents import create_custom_tools
from tools import ASTTools
from utils import get_llm_client, LLMConfig
from config import get_settings
from deepagents.backends import FilesystemBackend

# ğŸ” ç¡®ä¿ LangSmith Tracing é…ç½®ç”Ÿæ•ˆ
# å¦‚æœ .env ä¸­é…ç½®äº† LANGSMITH_TRACING=trueï¼Œè¿™äº›ä¼šè‡ªåŠ¨åŠ è½½
if os.getenv("LANGSMITH_TRACING", "").lower() in ("true", "1"):
    print("[OK] LangSmith Tracing enabled for subagent observation")
    print(f"   Project: {os.getenv('LANGSMITH_PROJECT', 'default')}")
    print(f"   View traces at: https://smith.langchain.com")
else:
    print("[INFO] LangSmith Tracing disabled. To observe subagents:")
    print("   1. Set LANGSMITH_TRACING=true in .env")
    print("   2. Set LANGSMITH_API_KEY=<your_key> in .env")
    print("   3. Restart langgraph dev")

# åŠ è½½é…ç½®
settings = get_settings()

# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
llm_config = LLMConfig(
    provider=settings.llm_provider,
    model=settings.llm_model,
    api_key=settings.llm_api_key,
    api_base=settings.llm_api_base,
    temperature=settings.llm_temperature,
    max_tokens=settings.llm_max_tokens
)
llm_client = get_llm_client(llm_config)

# åˆå§‹åŒ–ä»£ç åˆ†æå·¥å…·
ast_tools = ASTTools()
custom_tools = create_custom_tools(ast_tools=ast_tools)

# é…ç½® FilesystemBackendï¼ˆçœŸå®ç£ç›˜å­˜å‚¨ï¼‰
# ä½¿ç”¨é…ç½®çš„ workspace è·¯å¾„ï¼ˆæ”¯æŒåŠ¨æ€é…ç½®ï¼‰
workspace_dir = settings.get_workspace_dir()
workspace_dir.mkdir(parents=True, exist_ok=True)

# å…³é”®ï¼šä½¿ç”¨ virtual_mode=Trueï¼Œè®©è·¯å¾„ä»¥ / å¼€å¤´ï¼ˆè™šæ‹Ÿç»å¯¹è·¯å¾„ï¼‰
filesystem_backend = FilesystemBackend(
    root_dir=str(workspace_dir),
    virtual_mode=True  # å¯ç”¨è™šæ‹Ÿè·¯å¾„æ¨¡å¼
)
print(f"[OK] Workspace: {workspace_dir.absolute()}")
print(f"[OK] FilesystemBackend initialized (virtual_mode=True)")
if settings.workspace_dir:
    print(f"[INFO] Custom workspace configured via WORKSPACE_DIR: {settings.workspace_dir}")

# åˆ›å»ºç»Ÿä¸€ Agentï¼ˆä½¿ç”¨ DeepAgents åŸç”Ÿçš„æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼‰
agent = create_unified_chat_agent(
    llm=llm_client._client,  # ä¼ é€’å†…éƒ¨çš„ ChatOpenAI å®ä¾‹
    custom_tools=custom_tools,  # ä»£ç åˆ†æå·¥å…·
    backend=filesystem_backend,  # ä½¿ç”¨ FilesystemBackend æä¾› write_file/read_file ç­‰å·¥å…·
)
print(f"[OK] Agent created with FilesystemBackend + {len(custom_tools)} code analysis tools")

# Studio ä¼šè‡ªåŠ¨æ£€æµ‹è¿™ä¸ª 'agent' å˜é‡
__all__ = ["agent"]

